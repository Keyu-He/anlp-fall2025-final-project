# Environment Configuration Example for Sotopia Baseline Benchmark
# Copy this file to .env and fill in your API keys

# Required: OpenAI API Key (for gpt-4o model)
OPENAI_API_KEY=your_openai_api_key_here

# Optional: DeepSeek API Key (if using DeepSeek directly)
# Note: You may also use Together AI or OpenRouter for DeepSeek models
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Optional: Together AI API Key (for Together AI hosted models)
TOGETHER_API_KEY=your_together_api_key_here

# Optional: OpenRouter API Key (for OpenRouter hosted models)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Redis Configuration (for Sotopia)
# Default values should work for local Redis instance
REDIS_HOST=localhost
REDIS_PORT=6379

# Sotopia Configuration
# Set to 'true' to enable verbose logging
SOTOPIA_VERBOSE=false

# Model Configuration
# You can override the default models by setting these variables
# Default models: gpt-4o, deepseek/deepseek-r1-distill-llama-8b
# MODEL_1=gpt-4o
# MODEL_2=deepseek/deepseek-r1-distill-llama-8b

# Alternative DeepSeek model formats you can try:
# MODEL_2=together_ai/deepseek-ai/DeepSeek-R1-Distill-Llama-8B
# MODEL_2=openrouter/deepseek/deepseek-r1-distill-llama-8b

# Partner Model (used as the conversation partner in benchmarks)
# Default: together_ai/meta-llama/Llama-3-70b-chat-hf
# PARTNER_MODEL=together_ai/meta-llama/Llama-3-70b-chat-hf

# Evaluator Model (used to evaluate the conversations)
# Default: gpt-4o
# EVALUATOR_MODEL=gpt-4o
